name: CI

# Runs on every push and every pull request.
# Job execution order:
#
#   lint ──┐
#           ├──► standards-check ──┐
#   typecheck ──┘                   ├──► test ──► bench-regression
#                                   │
#   (standards-check runs in        │
#    parallel with typecheck)       │
#
# A commit is blocked if ANY job fails.

on:
  push:
    branches: ["**"]
  pull_request:
    branches: ["**"]

jobs:
  # ── 1. Formatting ─────────────────────────────────────────────────────────
  # Checks black + isort. Must pass before any other job proceeds.
  lint:
    name: "Format Check (black + isort)"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: black + isort check (Docker)
        run: |
          docker run --rm \
            -v "$PWD":/work -w /work \
            python:3.12-slim bash -lc \
            "pip install --no-cache-dir black==24.1.1 isort==5.13.2 >/dev/null \
             && black --check . && isort --check-only ."

  # ── 2. Static type check ──────────────────────────────────────────────────
  # Runs pyright in basic mode. Must pass before standards-check proceeds.
  typecheck:
    name: "Type Check (pyright)"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: pyright (Docker)
        run: |
          docker run --rm \
            -v "$PWD":/work -w /work \
            python:3.12-slim bash -lc \
            "export DEBIAN_FRONTEND=noninteractive; \
             apt-get update >/dev/null && \
             apt-get install -y --no-install-recommends libatomic1 nodejs npm >/dev/null && \
             pip install --no-cache-dir -r requirements.txt >/dev/null && \
             npm -g --silent install pyright@1.1.408 >/dev/null && \
             pyright"

  # ── 3. Coding standards check ─────────────────────────────────────────────
  # Enforces: no loose dicts, no Any, naming conventions, Pydantic patterns,
  # import hygiene, common anti-patterns (ruff rule sets B, C4, SIM, RUF, UP).
  # Runs after lint + typecheck pass.
  standards-check:
    name: "Coding Standards (ruff)"
    runs-on: ubuntu-latest
    needs: [lint, typecheck]
    steps:
      - uses: actions/checkout@v4

      - name: ruff — style, patterns, anti-patterns (Docker)
        run: |
          docker run --rm \
            -v "$PWD":/work -w /work \
            python:3.12-slim bash -lc \
            "pip install --no-cache-dir ruff==0.3.0 >/dev/null && \
             ruff check . \
               --select=E,W,F,UP,B,C4,SIM,RUF \
               --ignore=B008,UP011,E501,W293 \
               --output-format=concise"

      - name: Verify no raw dict payloads at Kafka/Redis boundaries
        # Grep for the banned patterns: dict[str, object] or dict[str, Any] used
        # as function parameter types in kafka.py, service.py, worker files.
        # Pydantic models must be used instead (ClickEvent, CachedURLPayload, etc.)
        run: |
          echo "=== Checking for banned loose-dict payload patterns ==="
          BANNED=$(grep -rn \
            --include="*.py" \
            -E ":\s*dict\[str,\s*(object|Any|str \| int)\]" \
            app/ services/ scripts/ \
            | grep -v "test_" \
            | grep -v "#.*noqa" \
            | grep -v "bench_regression_check" \
            || true)
          if [ -n "$BANNED" ]; then
            echo "FAIL: Found loose dict payload types (use Pydantic models instead):"
            echo "$BANNED"
            exit 1
          fi
          echo "OK: No banned loose-dict payload patterns found."

      - name: Verify no list[list[object]] analytics rows
        run: |
          echo "=== Checking for banned list[list[object]] patterns ==="
          BANNED=$(grep -rn \
            --include="*.py" \
            -E "list\[list\[object\]\]" \
            app/ services/ \
            || true)
          if [ -n "$BANNED" ]; then
            echo "FAIL: Found list[list[object]] (use a Pydantic model row type instead):"
            echo "$BANNED"
            exit 1
          fi
          echo "OK: No banned list[list[object]] patterns found."

      - name: Verify coding standards doc is present and non-empty
        run: |
          test -s docs/coding-standards.md || \
            (echo "FAIL: docs/coding-standards.md is missing or empty" && exit 1)
          echo "OK: coding-standards.md present."

      - name: Verify benchmark baselines file is present
        run: |
          test -s docs/bench_baselines.json || \
            (echo "FAIL: docs/bench_baselines.json is missing or empty" && exit 1)
          echo "OK: bench_baselines.json present."

  # ── 4. Functional tests ───────────────────────────────────────────────────
  # Starts only the test-profile services (db-test + redis-test), then runs
  # pytest directly in a Docker container against those services.
  # Does NOT start the full 15-container stack — that would time out on free runners.
  test:
    name: "Functional Tests (pytest)"
    runs-on: ubuntu-latest
    needs: [standards-check]
    steps:
      - uses: actions/checkout@v4

      - name: Prepare environment files
        run: |
          cp .env.ci .env
          cp .env.ci .env.test

      - name: Start test dependencies (db-test + redis-test)
        run: docker compose --profile test up -d db-test redis-test

      - name: Wait for db-test and redis-test to be healthy
        run: |
          for i in $(seq 1 30); do
            DB_HEALTH=$(docker inspect --format='{{.State.Health.Status}}' urlshortener-db-test 2>/dev/null || echo "starting")
            REDIS_HEALTH=$(docker inspect --format='{{.State.Health.Status}}' urlshortener-redis-test 2>/dev/null || echo "starting")
            echo "db-test=$DB_HEALTH  redis-test=$REDIS_HEALTH  ($i/30)"
            if [ "$DB_HEALTH" = "healthy" ] && [ "$REDIS_HEALTH" = "healthy" ]; then
              echo "All test dependencies healthy"; break
            fi
            sleep 5
          done
          DB_HEALTH=$(docker inspect --format='{{.State.Health.Status}}' urlshortener-db-test 2>/dev/null)
          REDIS_HEALTH=$(docker inspect --format='{{.State.Health.Status}}' urlshortener-redis-test 2>/dev/null)
          [ "$DB_HEALTH" = "healthy" ] && [ "$REDIS_HEALTH" = "healthy" ] || \
            (echo "FAIL: Test dependencies never became healthy" && exit 1)

      - name: Run pytest (Docker)
        run: |
          # Derive the network from the running test container (works regardless of project dir name)
          NET=$(docker inspect urlshortener-db-test \
            --format '{{range $k,$v := .NetworkSettings.Networks}}{{$k}}{{end}}' 2>/dev/null | head -1)
          echo "Using network: $NET"
          docker run --rm \
            --network "$NET" \
            --env-file .env.ci \
            -e DATABASE_URL=postgresql+asyncpg://test:test@urlshortener-db-test:5432/urlshortener_test \
            -e REDIS_URL=redis://urlshortener-redis-test:6379/0 \
            -v "$PWD":/work -w /work \
            python:3.12-slim bash -lc \
            "pip install --no-cache-dir -r requirements.txt >/dev/null && \
             pytest tests/ -v --tb=short"

      - name: Tear down
        if: always()
        run: docker compose --profile test down -v --remove-orphans

  # ── 5. Benchmark regression gate ─────────────────────────────────────────
  # Runs the full workflow benchmark (writer + reader + celebrity) and compares
  # per-scenario RPS against docs/bench_baselines_ci.json (conservative CI baselines).
  # Uses 50% tolerance — CI free runners are much slower than local machines.
  # Local dev uses bench_baselines.json at 15% via: make bench + bench_regression_check.py
  # Only runs after all tests pass.
  bench-regression:
    name: "Benchmark Regression Gate (make bench)"
    runs-on: ubuntu-latest
    needs: [test]
    steps:
      - uses: actions/checkout@v4

      - name: Prepare environment files
        run: |
          cp .env.ci .env
          cp .env.ci .env.test

      - name: Pull base images (warm up layer cache)
        run: |
          docker pull python:3.12-slim &
          docker pull postgres:16-alpine &
          docker pull redis:7-alpine &
          docker pull confluentinc/cp-kafka:7.6.0 &
          docker pull confluentinc/cp-zookeeper:7.6.0 &
          docker pull clickhouse/clickhouse-server:24.3 &
          docker pull nginx:alpine &
          wait
          echo "All base images pulled"

      - name: Build images
        run: docker compose build

      - name: Start stack
        run: docker compose up -d

      - name: Wait for app healthy
        run: |
          for i in $(seq 1 60); do
            if curl -sf http://localhost:8080/health >/dev/null 2>&1; then
              echo "App is healthy after $((i*5))s"; break
            fi
            echo "Waiting for app... ($i/60)"; sleep 5
          done
          curl -sf http://localhost:8080/health || \
            (echo "FAIL: App never became healthy after 5 min" && docker compose logs --tail=50 && exit 1)

      - name: Wait for Kafka + keygen to stabilise
        # Kafka and keygen need extra time after the app health check passes.
        # Without this, warmup POST requests fail (no Kafka producer, no keygen IDs)
        # which leaves reader/celebrity with 0 warm URLs and 0 RPS.
        run: |
          echo "Waiting 30s for Kafka + keygen to stabilise..."
          sleep 30
          echo "Verifying POST /api/shorten works before benchmark..."
          for i in $(seq 1 10); do
            CODE=$(curl -s -o /dev/null -w "%{http_code}" -X POST http://localhost:8080/api/shorten \
              -H "Content-Type: application/json" \
              -d '{"url": "https://example.com"}')
            if [ "$CODE" = "201" ]; then
              echo "POST /api/shorten returned 201 — stack ready"; break
            fi
            echo "POST returned $CODE, retrying ($i/10)..."; sleep 5
          done

      - name: Run benchmark (writer + reader + celebrity)
        # Reduced concurrency and warmup for CI free runners (2-core shared).
        # Celebrity pool size reduced to 3 to ensure warmup produces enough URLs.
        run: |
          docker run --rm --network host \
            -e BENCH_BASE_URL=http://localhost:8080 \
            -e BENCH_DURATION_SECONDS=15 \
            -e BENCH_TIMEOUT_SECONDS=5 \
            -e BENCH_WRITER_CONCURRENCY=3 \
            -e BENCH_READER_CONCURRENCY=10 \
            -e BENCH_CELEBRITY_CONCURRENCY=5 \
            -e BENCH_CELEBRITY_POOL_SIZE=3 \
            -e BENCH_WARMUP_URLS=20 \
            -v "$PWD":/work -w /work \
            python:3.12-slim bash -lc \
            "pip install --no-cache-dir httpx==0.26.0 >/dev/null && python scripts/bench_http.py" \
            | tee /tmp/bench_output.txt

      - name: Regression check (CI baselines, ≤50% tolerance)
        # Uses bench_baselines_ci.json — conservative baselines for GitHub Actions
        # free runners (2-core shared). Local dev uses bench_baselines.json at 15%.
        run: |
          docker run --rm \
            -v "$PWD":/work \
            -v /tmp/bench_output.txt:/tmp/bench_output.txt:ro \
            python:3.12-slim bash -lc \
            "python /work/scripts/bench_regression_check.py \
               --results /tmp/bench_output.txt \
               --baselines /work/docs/bench_baselines_ci.json \
               --tolerance 0.50"

      - name: Upload benchmark results as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bench-results-${{ github.sha }}
          path: /tmp/bench_output.txt
          retention-days: 30

      - name: Tear down
        if: always()
        run: docker compose down -v --remove-orphans
